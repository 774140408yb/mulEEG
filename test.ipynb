{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    \"\"\"A class used to build the feed-forward attention layer.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    return_sequences: bool, optional\n",
    "        If False, returns the calculated attention weighted sum of an ECG signal. (default: False)\n",
    "    dim: int, optional\n",
    "        The dimension of the attention layer. (default: 64)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    build(input_shape)\n",
    "        Sets the weights for calculating the attention layer.\n",
    "    call(x)\n",
    "        Calculates the attention weights.\n",
    "    get_config()\n",
    "        Useful for serialization of the attention layer.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_sequences: bool = False, dim: int = 64, **kwargs) -> None:\n",
    "\n",
    "        self.return_sequences = return_sequences\n",
    "        self.dim = dim\n",
    "        super(attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape: Tuple[int, int, int]) -> None:\n",
    "        \"\"\"Builds the attention layer.\n",
    "\n",
    "        alpha = softmax(V.T * tanh(W.T * x + b))\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        W: tf.Tensor\n",
    "            The weights of the attention layer.\n",
    "        b: tf.Tensor\n",
    "            The bias of the attention layer.\n",
    "        V: tf.Tensor\n",
    "            The secondary weights of the attention layer.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name=\"att_weight\", shape=(input_shape[-1], self.dim), initializer=\"normal\"\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name=\"att_bias\", shape=(input_shape[1], self.dim), initializer=\"zeros\"\n",
    "        )\n",
    "        self.V = self.add_weight(name=\"Vatt\", shape=(self.dim, 1), initializer=\"normal\")\n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"Calculates the attention weights.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: tf.Tensor\n",
    "            The input tensor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tf.Tensor\n",
    "            The attention weighted sum of the input tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        e = K.dot(e, self.V)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "\n",
    "        if self.return_sequences:\n",
    "            return output, a\n",
    "\n",
    "        return K.sum(output, axis=1), a\n",
    "\n",
    "    def get_config(self) -> Dict[List[Any]]:\n",
    "        \"\"\"Returns the config of the attention layer. Useful for serialization.\"\"\"\n",
    "\n",
    "        base_config = super().get_config()\n",
    "        config = {\n",
    "            \"return sequences\": tf.keras.initializers.serialize(self.return_sequences),\n",
    "            \"att dim\": tf.keras.initializers.serialize(self.dim),\n",
    "        }\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mulEEG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/zombie/mulEEG/test.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu/home/zombie/mulEEG/test.ipynb#ch0000001vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m resources\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu/home/zombie/mulEEG/test.ipynb#ch0000001vscode-remote?line=4'>5</a>\u001b[0m cfg \u001b[39m=\u001b[39m ConfigParser()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpu/home/zombie/mulEEG/test.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m resources\u001b[39m.\u001b[39mpath(\u001b[39m\"\u001b[39m\u001b[39mmulEEG\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mconfig.cfg\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m path:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu/home/zombie/mulEEG/test.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m     cfg\u001b[39m.\u001b[39mread(\u001b[39mstr\u001b[39m(path))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/contextlib.py?line=110'>111</a>\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/contextlib.py?line=111'>112</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/contextlib.py?line=112'>113</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/contextlib.py?line=113'>114</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/contextlib.py?line=114'>115</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/importlib/resources.py:184\u001b[0m, in \u001b[0;36mpath\u001b[0;34m(package, resource)\u001b[0m\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=174'>175</a>\u001b[0m \u001b[39m\"\"\"A context manager providing a file path object to the resource.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=175'>176</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=176'>177</a>\u001b[0m \u001b[39mIf the resource does not already exist on its own on the file system,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=180'>181</a>\u001b[0m \u001b[39mexiting).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=181'>182</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=182'>183</a>\u001b[0m resource \u001b[39m=\u001b[39m _normalize_path(resource)\n\u001b[0;32m--> <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=183'>184</a>\u001b[0m package \u001b[39m=\u001b[39m _get_package(package)\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=184'>185</a>\u001b[0m reader \u001b[39m=\u001b[39m _get_resource_reader(package)\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=185'>186</a>\u001b[0m \u001b[39mif\u001b[39;00m reader \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/importlib/resources.py:47\u001b[0m, in \u001b[0;36m_get_package\u001b[0;34m(package)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=44'>45</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m package\n\u001b[1;32m     <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=45'>46</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=46'>47</a>\u001b[0m     module \u001b[39m=\u001b[39m import_module(package)\n\u001b[1;32m     <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m module\u001b[39m.\u001b[39m__spec__\u001b[39m.\u001b[39msubmodule_search_locations \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/resources.py?line=48'>49</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m is not a package\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(package))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/__init__.py?line=124'>125</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/__init__.py?line=125'>126</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///home/zombie/miniconda3/envs/torch/lib/python3.8/importlib/__init__.py?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:973\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mulEEG'"
     ]
    }
   ],
   "source": [
    "from configparser import ConfigParser\n",
    "from importlib import resources\n",
    "\n",
    "\n",
    "cfg = ConfigParser()\n",
    "with resources.path(\"mulEEG\", \"config.cfg\") as path:\n",
    "    cfg.read(str(path))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91128505d9f99ea738af95183293a7ec1d5638a1bec15ce3b442263df2226332"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
